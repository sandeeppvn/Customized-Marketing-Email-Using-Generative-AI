{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae23c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import auc, balanced_accuracy_score, make_scorer, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c45190ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/vritansh/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Imports for sentiment analysis \n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a207f5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Authentication\n"
     ]
    }
   ],
   "source": [
    "# API keyws that yous saved earlier\n",
    "\n",
    "# api_key = \"insert yours\"\n",
    "# api_secrets = \"insert yours\"\n",
    "# access_token = \"insert yours\"\n",
    "# access_secret = \"insert yours\"\n",
    " \n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key,api_secrets)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    "api = tweepy.API(auth)\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print('Successful Authentication')\n",
    "except:\n",
    "    print('Failed authentication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c983f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(part,whole):\n",
    "     return 100 * float(part)/float(whole)\n",
    "\n",
    "def fetch_top_user_tweets():\n",
    "            keyword = \"tesla\"\n",
    "            noOfTweet = 10\n",
    "            # keyword = input('Please enter keyword or hashtag to search: ')\n",
    "            # noOfTweet = int(input ('Please enter how many tweets to analyze: '))\n",
    "            tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(noOfTweet)\n",
    "            positive = 0\n",
    "            negative = 0\n",
    "            neutral = 0\n",
    "            polarity = 0\n",
    "            tweet_list = []\n",
    "            neutral_list = []\n",
    "            negative_list = []\n",
    "            positive_list = []\n",
    "            positive_user = []\n",
    "            for tweet in tweets: \n",
    "              #print(tweet.text)\n",
    "              tweet_list.append(tweet.text)\n",
    "              analysis = TextBlob(tweet.text)\n",
    "              score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
    "              neg = score['neg']\n",
    "              neu = score['neu']\n",
    "              pos = score['pos']\n",
    "              comp = score['compound']\n",
    "              polarity += analysis.sentiment.polarity\n",
    "\n",
    "              if neg > pos:\n",
    "                negative_list.append(tweet.text)\n",
    "                negative += 1\n",
    "              elif pos > neg:\n",
    "                positive_list.append(tweet.text)\n",
    "                positive_user.append(tweet.user.id)\n",
    "                positive += 1\n",
    "\n",
    "              elif pos == neg:\n",
    "                neutral_list.append(tweet.text)\n",
    "                neutral += 1\n",
    "            positive = percentage(positive, noOfTweet)\n",
    "            negative = percentage(negative, noOfTweet)\n",
    "            neutral = percentage(neutral, noOfTweet)\n",
    "            polarity = percentage(polarity, noOfTweet)\n",
    "            positive = format(positive, '.1f')\n",
    "            negative = format(negative, '.1f')\n",
    "            neutral = format(neutral, '.1f')\n",
    "            \n",
    "            count=0\n",
    "            dicts = {}\n",
    "            for user in positive_user:\n",
    "              count=count+1\n",
    "              user_tweet = []\n",
    "              timeline=tweepy.Cursor(api.user_timeline, id=user).items(5)\n",
    "              for r in timeline:\n",
    "                user_tweet.append(r.text)\n",
    "                #print(r.text)\n",
    "              dicts[user] = user_tweet\n",
    "\n",
    "#               print(\"user {}\".format(count))\n",
    "\n",
    "\n",
    "            return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ad877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "loaded_model = joblib.load('customer_behavior_model.pkl')\n",
    "\n",
    "def make_prediction(new_data):\n",
    "    # All the columns that are expected by the model\n",
    "    cols = ['Age', 'EstimatedSalary', 'Gender_Female', 'Profession_Artist',\n",
    "            'Profession_Doctor', 'Profession_Engineer', 'Profession_Entertainment',\n",
    "            'Profession_Executive', 'Profession_Healthcare', 'Profession_Homemaker',\n",
    "            'Profession_Lawyer', 'Profession_Marketing', 'Ever_Married_Yes',\n",
    "            'Spending_Score_Average', 'Spending_Score_High', 'Spending_Score_Low']\n",
    "\n",
    "    # Encoding the categorical variables and adding the missing columns\n",
    "    new_data_enc = pd.get_dummies(new_data, columns=['Gender', 'Profession', 'Ever_Married', 'Spending_Score'])\n",
    "    new_data_enc = new_data_enc.reindex(columns=cols, fill_value=0)\n",
    "\n",
    "\n",
    "    # Making predictions\n",
    "    predictions = loaded_model.predict(new_data_enc)\n",
    "\n",
    "    return bool(predictions[0])  # Convert 0/1 to True/False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54708b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://10.206.2.225:4000/ (Press CTRL+C to quit)\n",
      "Unexpected parameter: id\n",
      "Unexpected parameter: id\n",
      "Unexpected parameter: id\n",
      "Unexpected parameter: id\n",
      "10.206.2.225 - - [12/Jun/2023 21:22:19] \"POST /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @caroljsroth: As I share in \"You Will Own Nothing\" (out 7/18), after @ElonMusk wanted to bring free speech to Twitter, he was punished bâ€¦\n"
     ]
    }
   ],
   "source": [
    "# {\n",
    "#     \"Age\": 30,\n",
    "#     \"Gender\": \"Male\",\n",
    "#     \"Purchased\": true,\n",
    "#     \"EstimatedSalary\": 200000,\n",
    "#     \"Profession\": \"Entertainment\",\n",
    "#     \"Ever_Married\": false,\n",
    "#     \"Spending_Score\": \"High\"\n",
    "# }\n",
    "\n",
    "@app.route('/generate', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "  \n",
    "    age = data.get('Age')\n",
    "    gender = data.get('Gender')\n",
    "    purchased = data.get('Purchased')\n",
    "    estimated_salary = data.get('EstimatedSalary')\n",
    "    profession = data.get('Profession')\n",
    "    Ever_Married = data.get('Ever_Married')\n",
    "    Spending_Score = data.get('Spending_Score')\n",
    "      \n",
    "    #twitter_handle = data.get('twitterHandle') \n",
    "    \n",
    "    twitterhandle = data.get('twitter_handle')\n",
    "    \n",
    "    new_data = pd.DataFrame({\n",
    "    'Age': [age],\n",
    "    'EstimatedSalary': [estimated_salary],\n",
    "    'Purchased': [purchased],\n",
    "    'Gender': [gender],\n",
    "    'Profession': [profession],\n",
    "    'Ever_Married': [Ever_Married],\n",
    "    'Spending_Score': [Spending_Score]\n",
    "    })\n",
    "\n",
    "    \n",
    "    prediction =  make_prediction(new_data)\n",
    "    \n",
    "    s = fetch_top_user_tweets()\n",
    "    if(len(list(s.keys())) >0):\n",
    "        first_user = list(s.keys())[0]\n",
    "        tweet_1 = s[first_user][0]\n",
    "    print(tweet_1)\n",
    "    \n",
    "    return str(prediction)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=4000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc08ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
