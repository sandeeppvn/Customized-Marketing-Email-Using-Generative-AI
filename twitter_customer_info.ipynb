{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjN734ykKyic",
    "outputId": "8ea49120-96c1-4540-eaac-e7db74e9e9c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (4.12.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "\u001b[33mWARNING: Error parsing requirements for moviepy: [Errno 2] No such file or directory: '/Users/vritansh/opt/anaconda3/lib/python3.9/site-packages/moviepy-1.0.3.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: nltk in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: joblib in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: click in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for moviepy: [Errno 2] No such file or directory: '/Users/vritansh/opt/anaconda3/lib/python3.9/site-packages/moviepy-1.0.3.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.8/636.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: click in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: joblib in /Users/vritansh/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for moviepy: [Errno 2] No such file or directory: '/Users/vritansh/opt/anaconda3/lib/python3.9/site-packages/moviepy-1.0.3.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/vritansh/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#installing relevant libraries\n",
    "!pip install tweepy\n",
    "!pip install nltk\n",
    "!pip install textblob\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7ePiFrnBKrdF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/vritansh/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSHu9ItdK-Rc",
    "outputId": "ab1fbdec-024c-4503-8433-dc424b8e3ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Authentication\n"
     ]
    }
   ],
   "source": [
    "# setting up twitter api authentication\n",
    "\n",
    "# API keyws that yous saved earlier\n",
    "api_key = \"TxzOEBKMfA7HY2Vf37hrWLo3V\"\n",
    "api_secrets = \"XNXJmrARDgAoUxPZi3IqlSQbDVjZjTKRd6Qiw7y0LJuyJlVd3C\"\n",
    "access_token = \"241533436-nN0A7PdYXlv41FVYb40NKCi0N0Yi9JO3Yw0AdGFG\"\n",
    "access_secret = \"EvYBNpXMxy35v1DkmICWiJDgMiwL3RWhhBaSuHRxPcmT2\"\n",
    "\n",
    "# api_key = \"insert yours\"\n",
    "# api_secrets = \"insert yours\"\n",
    "# access_token = \"insert yours\"\n",
    "# access_secret = \"insert yours\"\n",
    " \n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key,api_secrets)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    "api = tweepy.API(auth)\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print('Successful Authentication')\n",
    "except:\n",
    "    print('Failed authentication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrT1kKcgK-vM",
    "outputId": "dad95466-5272-4765-ad50-72d8c307cdcf"
   },
   "outputs": [],
   "source": [
    "def percentage(part,whole):\n",
    "     return 100 * float(part)/float(whole)\n",
    "\n",
    "def fetch_top_user_tweets():\n",
    "            keyword = \"tesla\"\n",
    "            noOfTweet = 10\n",
    "            # keyword = input('Please enter keyword or hashtag to search: ')\n",
    "            # noOfTweet = int(input ('Please enter how many tweets to analyze: '))\n",
    "            tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(noOfTweet)\n",
    "            positive = 0\n",
    "            negative = 0\n",
    "            neutral = 0\n",
    "            polarity = 0\n",
    "            tweet_list = []\n",
    "            neutral_list = []\n",
    "            negative_list = []\n",
    "            positive_list = []\n",
    "            positive_user = []\n",
    "            for tweet in tweets: \n",
    "              #print(tweet.text)\n",
    "              tweet_list.append(tweet.text)\n",
    "              analysis = TextBlob(tweet.text)\n",
    "              score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
    "              neg = score['neg']\n",
    "              neu = score['neu']\n",
    "              pos = score['pos']\n",
    "              comp = score['compound']\n",
    "              polarity += analysis.sentiment.polarity\n",
    "\n",
    "              if neg > pos:\n",
    "                negative_list.append(tweet.text)\n",
    "                negative += 1\n",
    "              elif pos > neg:\n",
    "                positive_list.append(tweet.text)\n",
    "                positive_user.append(tweet.user.id)\n",
    "                positive += 1\n",
    "\n",
    "              elif pos == neg:\n",
    "                neutral_list.append(tweet.text)\n",
    "                neutral += 1\n",
    "            positive = percentage(positive, noOfTweet)\n",
    "            negative = percentage(negative, noOfTweet)\n",
    "            neutral = percentage(neutral, noOfTweet)\n",
    "            polarity = percentage(polarity, noOfTweet)\n",
    "            positive = format(positive, '.1f')\n",
    "            negative = format(negative, '.1f')\n",
    "            neutral = format(neutral, '.1f')\n",
    "            \n",
    "            count=0\n",
    "            dicts = {}\n",
    "            for user in positive_user:\n",
    "              count=count+1\n",
    "              user_tweet = []\n",
    "              timeline=tweepy.Cursor(api.user_timeline, id=user).items(5)\n",
    "              for r in timeline:\n",
    "                user_tweet.append(r.text)\n",
    "                #print(r.text)\n",
    "              dicts[user] = user_tweet\n",
    "\n",
    "#               print(\"user {}\".format(count))\n",
    "            return dicts\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected parameter: id\n"
     ]
    }
   ],
   "source": [
    "s = fetch_top_user_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@garyblack00 @JPSartre_NoExit @SawyerMerritt @EmmetPeppers @Tesla @elonmusk @p_ferragu @DivesTech Yep exactly - and… https://t.co/jiC8KQ1U2p'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5r7KTLnR3iNK",
    "outputId": "1b362a9f-c134-4bff-8c70-b94d78895abe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected parameter: id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965387535638700032\n",
      "user 1\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "dicts = {}\n",
    "for user in positive_user:\n",
    "  count=count+1\n",
    "  user_tweet = []\n",
    "  timeline=tweepy.Cursor(api.user_timeline, id=user).items(5)\n",
    "  for r in timeline:\n",
    "    user_tweet.append(r.text)\n",
    "    #print(r.text)\n",
    "  dicts[user] = user_tweet\n",
    "  \n",
    "  print(\"user {}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MS74yvxZJCbz",
    "outputId": "8af0f569-9bd3-44db-c0d1-896a60ff4cce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{965387535638700032: [\"RT @Barchart: Tesla $TSLA has now traded green for 12 consecutive days, the longest winning streak in the company's history https://t.co/sS…\",\n",
       "  \"RT @KobeissiLetter: Heading into the Fed meeting on Wednesday, we have some of the most split rate probabilities we have seen.\\n\\nThere's now…\",\n",
       "  \"RT @Barchart: JP Morgan's prediction for how the S&amp;P 500 will react to this week's CPI reading.  Warning: JP Morgan tends to get these almo…\",\n",
       "  'you decide',\n",
       "  \"I'll let the twitter twitter community decide \\n\\npoll in the quoted retweet https://t.co/Ar8RAFHjgL\"]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary of users and tweets made by users \n",
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
